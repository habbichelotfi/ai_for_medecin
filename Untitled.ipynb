{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a94c2b2",
   "metadata": {},
   "source": [
    "# Chest X-Ray Medical Diagnosis with Deep Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e8a9e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-13 09:57:15.924464: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-12-13 09:57:15.924492: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import sklearn\n",
    "import shap\n",
    "import os\n",
    "import seaborn as sns\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "sns.set()\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [10, 7]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15d95def",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f77a430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read csv file containing training datadata\n",
    "train_df = pd.read_csv(\"nih_new/train-small.csv\")\n",
    "valid_df = pd.read_csv(\"nih_new/valid-small.csv\")\n",
    "test_df = pd.read_csv(\"nih_new/test.csv\")\n",
    "print(f'There are {train_df.shape[0]} rows and {train_df.shape[1]} columns in the train data frame')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3a904e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train set: The total patient ids are {train_df['PatientId'].count()}, from those the unique ids are {train_df['PatientId'].value_counts().shape[0]} \")\n",
    "print(f\"Validation set: The total patient ids are {valid_df['PatientId'].count()}\")\n",
    "print(f\"Test set: The total patient ids are {test_df['PatientId'].count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad102f89",
   "metadata": {},
   "source": [
    "## Checking if there is leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727190fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_for_leakage(df1, df2, patient_col):\n",
    "    \"\"\"\n",
    "    Return True if there any patients are in both df1 and df2.\n",
    "\n",
    "    Args:\n",
    "        df1 (dataframe): dataframe describing first dataset\n",
    "        df2 (dataframe): dataframe describing second dataset\n",
    "        patient_col (str): string name of column with patient IDs\n",
    "    \n",
    "    Returns:\n",
    "        leakage (bool): True if there is leakage, otherwise False\n",
    "    \"\"\"\n",
    "    \n",
    "    df1_patients_unique = set(df1[patient_col])\n",
    "    df2_patients_unique = set(df2[patient_col])\n",
    "    \n",
    "    patients_in_both_groups = list(df1_patients_unique.intersection(df2_patients_unique))\n",
    "\n",
    "    # leakage contains true if there is patient overlap, otherwise false.\n",
    "    leakage = len(patients_in_both_groups) > 0 \n",
    "        \n",
    "    return leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc35d342",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"leakage between train and test: {}\".format(check_for_leakage(train_df, test_df, 'PatientId')))\n",
    "print(\"leakage between valid and test: {}\".format(check_for_leakage(valid_df, test_df, 'PatientId')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7b6be5",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09766307",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = train_df.keys()\n",
    "columns = list(columns)\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f07199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove unnecesary elements\n",
    "columns.remove('Image')\n",
    "columns.remove('PatientId')\n",
    "# Get the total classes\n",
    "print(f\"There are {len(columns)} columns of labels for these conditions: {columns}\")\n",
    "# Print out the number of positive labels for each class\n",
    "for column in columns:\n",
    "    print(f\"The class {column} has {train_df[column].sum()} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed054458",
   "metadata": {},
   "source": [
    "## Data Visualization\n",
    "Using the image names listed in the csv file, retrieve the image associated with each row of data in your dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29becd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract numpy values from Image column in data frame\n",
    "images = train_df['Image'].values\n",
    "\n",
    "# Extract 9 random images from it\n",
    "random_images = [np.random.choice(images) for i in range(9)]\n",
    "\n",
    "# Location of the image dir\n",
    "img_dir = 'nih_new/images-small/'\n",
    "\n",
    "print('Display Random Images')\n",
    "\n",
    "# Adjust the size of your images\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "# Iterate and plot random images\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    img = plt.imread(os.path.join(img_dir, random_images[i]))\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.axis('off')\n",
    "    \n",
    "# Adjust subplot parameters to give specified padding\n",
    "plt.tight_layout()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a1c303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first image that was listed in the train_df dataframe\n",
    "sample_img = train_df.Image[0]\n",
    "raw_image = plt.imread(os.path.join(img_dir, sample_img))\n",
    "plt.imshow(raw_image, cmap='gray')\n",
    "plt.grid(color='w', linestyle='-', linewidth=1)\n",
    "plt.colorbar()\n",
    "plt.title('Raw Chest X Ray Image')\n",
    "print(f\"The dimensions of the image are {raw_image.shape[0]} pixels width and {raw_image.shape[1]} pixels height, one single color channel\")\n",
    "print(f\"The maximum pixel value is {raw_image.max():.4f} and the minimum is {raw_image.min():.4f}\")\n",
    "print(f\"The mean value of the pixels is {raw_image.mean():.4f} and the standard deviation is {raw_image.std():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5619be77",
   "metadata": {},
   "source": [
    "# Image processing using Keras\n",
    "### Standardization\n",
    "\n",
    "Normalizing images is better suited for training a convolutional neural network. For this task we use the Keras [ImageDataGenerator](https://keras.io/preprocessing/image/) function to perform data preprocessing and data augmentation.\n",
    "The `image_generator` will adjust the image data such that the new mean of the data will be zero, and the standard deviation of the data will be 1.  \n",
    "\n",
    "In other words, the generator will replace each pixel value in the image with a new value calculated by subtracting the mean and dividing by the standard deviation.\n",
    "\n",
    "$$\\frac{x_i - \\mu}{\\sigma}$$\n",
    "\n",
    "Create an image generator for preprocessing. Pre-process the data using the `image_generator`as well as reduce the image size down to 320x320 pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02b6e9e8",
   "metadata": {},
   "source": [
    "# Import data generator from keras \n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a3b67b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6839d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_generator(df, image_dir, x_col, y_cols, shuffle=True, batch_size=8, seed=1, target_w = 320, target_h = 320):\n",
    "    \"\"\"\n",
    "    Return generator for training set, normalizing using batch\n",
    "    statistics.\n",
    "\n",
    "    Args:\n",
    "      train_df (dataframe): dataframe specifying training data.\n",
    "      image_dir (str): directory where image files are held.\n",
    "      x_col (str): name of column in df that holds filenames.\n",
    "      y_cols (list): list of strings that hold y labels for images.\n",
    "      batch_size (int): images per batch to be fed into model during training.\n",
    "      seed (int): random seed.\n",
    "      target_w (int): final width of input images.\n",
    "      target_h (int): final height of input images.\n",
    "    \n",
    "    Returns:\n",
    "        train_generator (DataFrameIterator): iterator over training set\n",
    "    \"\"\"        \n",
    "    print(\"getting train generator...\") \n",
    "    # Normalize images  --- Generate batches of tensor image data with real-time data augmentation\n",
    "    image_generator = ImageDataGenerator(\n",
    "        samplewise_center=True,              #Set each sample mean to 0\n",
    "        samplewise_std_normalization= True)  # Divide each input by its standard deviation\n",
    "    \n",
    "    # flow from directory with specified batch size and target image size\n",
    "    # flow_from_dataframe ==> https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\n",
    "    # RETURNS a DataFrameIterator yielding tuples of (x, y) where x is a numpy array containing a batch of images with \n",
    "    # shape (batch_size, *target_size, channels) and y is a numpy array of corresponding labels\n",
    "    # default data format of ImageGenerator is channels_last\n",
    "    generator = image_generator.flow_from_dataframe(\n",
    "            dataframe=df,\n",
    "            directory=image_dir,\n",
    "            x_col=x_col,\n",
    "            y_col=y_cols,\n",
    "            class_mode=\"raw\",       #  Mode for yielding the targets, one of \"binary\", \"categorical\", \"input\", \"multi_output\", \"raw\", sparse\" or None. Default: \"categorical\".\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            seed=seed,\n",
    "            target_size=(target_w,target_h))\n",
    "    \n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1af82dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_and_valid_generator(valid_df, test_df, train_df, image_dir, x_col, y_cols, sample_size=100, batch_size=8, \n",
    "                                 seed=1, target_w = 320, target_h = 320):\n",
    "    \"\"\"\n",
    "    Return generator for validation set and test test set using \n",
    "    normalization statistics from training set.\n",
    "\n",
    "    Args:\n",
    "      valid_df (dataframe): dataframe specifying validation data.\n",
    "      test_df (dataframe): dataframe specifying test data.\n",
    "      train_df (dataframe): dataframe specifying training data.\n",
    "      image_dir (str): directory where image files are held.\n",
    "      x_col (str): name of column in df that holds filenames.\n",
    "      y_cols (list): list of strings that hold y labels for images.\n",
    "      sample_size (int): size of sample to use for normalization statistics.\n",
    "      batch_size (int): images per batch to be fed into model during training.\n",
    "      seed (int): random seed.\n",
    "      target_w (int): final width of input images.\n",
    "      target_h (int): final height of input images.\n",
    "    \n",
    "    Returns:\n",
    "        test_generator (DataFrameIterator) and valid_generator: iterators over test set and validation set respectively\n",
    "    \"\"\"\n",
    "    # get generator to sample dataset\n",
    "    print(f\"\\nextracting {sample_size} train images to normalize validation and test datasets...\")\n",
    "\n",
    "    raw_train_generator = ImageDataGenerator().flow_from_dataframe(\n",
    "        dataframe=train_df, \n",
    "        directory=IMAGE_DIR, \n",
    "        x_col=\"Image\", \n",
    "        y_col=labels, \n",
    "        class_mode=\"raw\", \n",
    "        batch_size=sample_size, \n",
    "        shuffle=True, \n",
    "        target_size=(target_w, target_h))\n",
    "    \n",
    "    # get data sample\n",
    "    batch = raw_train_generator.next() # generate a batch of samples and associated labels \n",
    "    data_sample = batch[0]             # => we need only the sample imgs ie batch[0]\n",
    "\n",
    "    # use sample to fit mean and std for test set generator\n",
    "    image_generator = ImageDataGenerator(\n",
    "        featurewise_center=True,\n",
    "        featurewise_std_normalization= True)\n",
    "    \n",
    "    # fit generator to sample from training data - we use this generator normalizing mean and std using the train sample of 100\n",
    "    image_generator.fit(data_sample)\n",
    "    \n",
    "    print(\"\\ngetting valid generator...\")\n",
    "\n",
    "    # get test generator\n",
    "    valid_generator = image_generator.flow_from_dataframe(\n",
    "            dataframe=valid_df,\n",
    "            directory=image_dir,\n",
    "            x_col=x_col,\n",
    "            y_col=y_cols,\n",
    "            class_mode=\"raw\",\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            seed=seed,\n",
    "            target_size=(target_w,target_h))\n",
    "    \n",
    "    print(\"\\ngetting test generator...\")\n",
    "    test_generator = image_generator.flow_from_dataframe(\n",
    "            dataframe=test_df,\n",
    "            directory=image_dir,\n",
    "            x_col=x_col,\n",
    "            y_col=y_cols,\n",
    "            class_mode=\"raw\",\n",
    "            batch_size=batch_size,\n",
    "            shuffle=False,\n",
    "            seed=seed,\n",
    "            target_size=(target_w,target_h))\n",
    "    return valid_generator, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0cd324",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Cardiomegaly', 'Emphysema', 'Effusion', 'Hernia', 'Infiltration', 'Mass', 'Nodule', 'Atelectasis',\n",
    "              'Pneumothorax', 'Pleural_Thickening', 'Pneumonia', 'Fibrosis', 'Edema', 'Consolidation']\n",
    "IMAGE_DIR = \"nih_new/images-small/\"\n",
    "train_generator = get_train_generator(train_df, IMAGE_DIR, \"Image\", labels)\n",
    "valid_generator, test_generator= get_test_and_valid_generator(valid_df, test_df, train_df, IMAGE_DIR, \"Image\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de4a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a processed image\n",
    "sns.set_style(\"white\")\n",
    "generated_image, label = train_generator.__getitem__(0)\n",
    "plt.imshow(generated_image[0], cmap='gray')\n",
    "plt.colorbar()\n",
    "plt.title('Raw Chest X Ray Image')\n",
    "print(f\"The dimensions of the image are {generated_image.shape[1]} pixels width and {generated_image.shape[2]} pixels height\")\n",
    "print(f\"The maximum pixel value is {generated_image.max():.4f} and the minimum is {generated_image.min():.4f}\")\n",
    "print(f\"The mean value of the pixels is {generated_image.mean():.4f} and the standard deviation is {generated_image.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1307bfe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27545ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddee6b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abe1c7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280f5708",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
